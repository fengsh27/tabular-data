import os
import shutil
import os.path as path
import csv
from typing import Any
import pandas as pd

"""
This module is to pre-process tables generated by LLMs(ChatGPT/Gemini) to 
normalize them to facilitate benchmark.
"""

# ==============================================================
# PK summary table columns
# ==============================================================
PK_SUMMARY_COLUMNS = [
    "Drug name",
    "Analyte",
    "Specimen",
    "Population",
    "Pregnancy stage",
    "Summary statistics",
    "Parameter type",
    "Value",
    "Unit",
    "Subject N",
    "Variation value",
    "Variation type",
    "P value",
    "Interval type",
    "Lower limit",
    "High limit",
]
LOWER_PK_SUMMARY_COLUMNS = [x.lower() for x in PK_SUMMARY_COLUMNS]

PK_SUMMARY_COLUMNS_MAP = [
    ("P-value", "P value"),
    ("Subjectsn", "Subject N"),
    ("Subjects n", "Subject N"),
    ("Interval low", "Lower limit"),
    ("interval high", "High limit"),
    ("Variability statistic", "Variation type"),
    ("Summary Statistic", "Summary statistics"),
    ("Parameter unit", "Unit"),
    ("Parameter statistic", "Summary statistics"),
    ("Parameter value", "Value"),
    ("Lower bound", "Lower limit"),
    ("Upper bound", "High limit"),
]

# ==============================================================
# PK individual baseline table columns
# ==============================================================
PK_INDIVIDUAL_BASELINE_COLUMNS = [
    "Patient ID",
    "Drug name",
    "Analyte",
    "Specimen",
    "Population",
    "Pregnancy stage",
    "Pediatric/Gestational age",
    "Parameter type",
    "Parameter unit",
    "Parameter value",
    "Time value",
    "Time unit",
]

LOWER_PK_INDIVIDUAL_BASELINE_COLUMNS = [x.lower() for x in PK_INDIVIDUAL_BASELINE_COLUMNS]

PK_INDIVIDUAL_BASELINE_COLUMNS_MAP = []

# ==============================================================
# functions
# ==============================================================

def ensure_columns(
    df_table: pd.DataFrame,
    columns: list[str] = PK_SUMMARY_COLUMNS,
    columns_map: dict[str, str] = PK_SUMMARY_COLUMNS_MAP
) -> pd.DataFrame:
    """ Normalize pk summary columns """
    # Normalize column name
    col_map = {}
    for item in columns_map:
        col_map[item[0]] = item[1]

    df_table = df_table.rename(columns=col_map)
    
    # Normalize column name for the following cases:
    # (1) lower case and upper case difference
    # (2) spaces at the begining or end of column name
    lower_columns = [col.lower() for col in columns]
    col_map = {}
    for col in df_table:
        if col in columns:
            continue
        if col.lower() in lower_columns:
            ix = lower_columns.index(col.lower())
            col_map[col] = columns[ix]
        if col.strip().lower() in lower_columns:
            ix = lower_columns.index(col.strip().lower())
            col_map[col] = columns[ix]
    if len(col_map.keys()) > 0:
        df_table = df_table.rename(columns=col_map)

    df_table = df_table[df_table.columns.intersection(columns)]

    return df_table

def ensure_NO_column(
    df_table: pd.DataFrame,
    first_column_name: str = LOWER_PK_SUMMARY_COLUMNS[0]
) -> pd.DataFrame:
    """ Ensure the first column is "NO." column """
    if df_table.columns[0].lower() == first_column_name:
        # No "NO." column
        df_table.insert(0, "NO.", range(len(df_table)))
    
    return df_table

def normalize_decimal_dot(text: Any) -> Any:
    """Convert middle dots (·, ∙, •) used as decimal separators to '.'"""
    if not isinstance(text, str):
        return text
    return text.replace("·", ".").replace("∙", ".").replace("•", ".")

def normalize_dataframe_string_values(df: pd.DataFrame) -> pd.DataFrame:
    """ Normalize string values """
    for col in df.columns:
        if df[col].dtype == "object":
            df[col] = df[col].apply(lambda x: normalize_decimal_dot(str(x).strip()) if pd.notna(x) else x)
    return df
    
def preprocess_pk_summary_table(csv_file: str) -> pd.DataFrame:
    """ preprocess pk summary table """
    df_table = pd.read_csv(csv_file)
    df_table = ensure_columns(df_table)
    df_table = ensure_NO_column(df_table)    

    return df_table

def preprocess_pk_individual_table(csv_file: str) -> pd.DataFrame:
    df_table = pd.read_csv(csv_file)
    df_table = ensure_columns(
        df_table,
        columns=PK_INDIVIDUAL_BASELINE_COLUMNS,
        columns_map=PK_INDIVIDUAL_BASELINE_COLUMNS_MAP
    )
    df_table = ensure_NO_column(
        df_table,
        first_column_name=LOWER_PK_INDIVIDUAL_BASELINE_COLUMNS[0]
    )
    df_table = normalize_dataframe_string_values(df_table)
    return df_table

def preprocess_pk_summary_csv_file(pk_csv_file: str):
    bn, extname = path.splitext(pk_csv_file)
    orig_file = f"{bn}-original{extname}"
    try:
        if not os.path.exists(orig_file):
            shutil.copyfile(pk_csv_file, orig_file)
    except Exception as e:
        print(str(e))
        return False

    dst_file = pk_csv_file
    output_df = preprocess_pk_summary_table(orig_file)

    # before write to csv file, remove the first column,
    output_df = output_df.iloc[:, 1:]
    output_df.to_csv(dst_file, sep=",")
    return True

def preprocess_pk_individual_csv_file(pk_csv_file: str):
    df_table = pd.read_csv(pk_csv_file)
    df_table = ensure_columns(df_table)
    df_table = ensure_NO_column(df_table)
    return df_table


if __name__ == "__main__":
    # process_single_file()
    df = preprocess_pk_individual_table("benchmark/data/pk-individual/2025-10-25-mas/10971311_gpt4o.csv")
    print(df)
